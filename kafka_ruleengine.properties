# properties file for Java Rule Engine (JaRE) Kafka service

# list of kafka brokers separated by a comma (no spaces).
kafka.brokers=localhost:9092

# the kafka group id
kafka.group.id=group_006

# the kafka source topic to read from
# note: the message value must be in JSON or CSV format
kafka.topic.source=travel_discount

# the format of the messages of the source topic.
# possible values are
#   json
#   avro
#   csv
kafka.topic.source.format=json

# the format of the messages of all output topics.
# possible values are
#   json
#   avro
kafka.topic.output.format=json

# when kafka.topic.source.format is set to "csv" define the names
# of the individual fields here. Field names must be separated by
# a comma (no spaces) and are case sensitive
kafka.topic.source.format.csv.fields=

# when kafka.topic.source.format is set to "csv" define the separator
# that is used to separate the values/fields of the data row
# Note: make sure that the separator defined here does not occur within
#       the values of the fields themselves.
kafka.topic.source.format.csv.value.separator=

# when kafka.topic.source.format is set to "avro" define the name of
# the avro schema - only if no schema registry is used. specify the full 
# path and filename.
# Note: if no registry is used
kafka.topic.source.format.avro.schema.name=

# the kafka topic for the output of the messages.
# if the failed topic is NOT specified, then all messages
# are sent to the this topic as well, unless kafka topic.dropfailed.
# is set to true
kafka.topic.target=travel_discount_ruleengine

# setting if the failed messages should always be dropped and not be
# sent to the target topic and not to the failed topic.
# remark: this does not affect the logging topic
kafka.topic.dropfailed=false

# the kafka topic for the output of failed messages.
# if this topic is NOT specified, then all messages (passed and failed)
# are sent to the topic specified in: kafka.topic.target or the failed
# ones are dropped, if kafka.topic.dropfailed is set to true.
# remark: makes no sense setting this if kafka.topic.dropfailed is set to true
kafka.topic.target.failed=

# fields that shall be excluded from the output to the output topics
# fields must be separated by a comma (no spaces) and are case sensitive
kafka.topic.exclude.fields=

# mode determines when the data is considered as failed
# 0 = specify the minimum number of groups that must have failed in: ruleengine.failed.minimum_number_of_groups
# 1 = failed when at least 1 rulegroup failed
# 2 = failed when all rulegroups failed
ruleengine.failed.mode=2

# the minimum number of groups that must have failed to consider
# the the data as failed. 
# only used if: ruleengine.failed.mode=0
ruleengine.failed.minimum_number_of_groups=

# how often - in seconds - the program should check
# for a modified ruleengine project zip file.
# if a changed file is detected, the program will pause processing
# and reload this file and the continue to process data
ruleengine.check.modified.file.interval=600

# the kafka topic for the output of the ruleengine detailed results.
# if this topic is not specified no detailed output will be done.
kafka.topic.target.logging=

# the type of messages to output to the topic specified
# in: kafka.topic.target.logging
# possible values are:
#   0 = passed and failed messages
#   1 = passed messages only
#   2 = failed messages only
kafka.topic.target.logging.type=0

# a field name that is used as a basis for counting messages.
# if the fields value changes, the counter for the messages is
# reset to zero. this value will be written to the log after the number
# of messages received specified in: kafka.topic.message.counter.logging.interval
kafka.topic.message.counter.fieldname=batch_id

# after how many total processed messages will the value of the
# counter for the field: kafka.topic.message.counter.fieldname 
# be written to the log
kafka.topic.message.counter.logging.interval=10

# after how many seconds where no messages have been received will
# the value of the counter for the field: kafka.topic.message.counter.fieldname 
# be written to the log (one time)
# this assures that after the given time, even if no further
# messages have been received, the field counter is written
# to the log
kafka.topic.message.counter.logging.idletime=30

